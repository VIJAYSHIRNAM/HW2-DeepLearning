{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vYiZq0X2oB5t"
   },
   "source": [
    "# **CSCE 5218 / CSCE 4930 Deep Learning**\n",
    "\n",
    "# **HW1a The Perceptron** (20 pt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vGVmKzgG2Ium",
    "outputId": "4cc2ca21-861a-4fba-a38c-83e3ec04bec8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A1\tA2\tA3\tA4\tA5\tA6\tA7\tA8\tA9\tA10\tA11\tA12\tA13\n",
      "1\t1\t1\t1\t0\t0\t1\t1\t0\t0\t0\t1\t1\t0\n",
      "0\t0\t0\t1\t0\t0\t1\t1\t0\t1\t0\t0\t1\t0\n",
      "0\t1\t1\t1\t0\t1\t1\t1\t1\t0\t0\t0\t1\t0\n",
      "0\t1\t1\t0\t1\t0\t1\t1\t1\t0\t1\t0\t1\t0\n",
      "0\t1\t0\t0\t0\t1\t0\t1\t0\t1\t0\t0\t1\t0\n",
      "0\t1\t1\t0\t0\t1\t1\t1\t1\t1\t1\t0\t1\t0\n",
      "0\t1\t1\t1\t0\t0\t1\t1\t0\t0\t0\t1\t1\t0\n",
      "0\t1\t0\t0\t1\t0\t0\t1\t1\t0\t1\t1\t1\t0\n",
      "1\t1\t1\t1\t0\t0\t1\t1\t0\t0\t0\t0\t1\t0\n",
      "1\t0\t1\t1\t1\t1\t1\t0\t0\t0\t0\t0\t1\t0\n",
      "1\t0\t0\t0\t1\t0\t0\t1\t1\t0\t1\t1\t1\t0\n",
      "0\t0\t1\t0\t0\t1\t1\t0\t0\t0\t0\t1\t1\t0\n",
      "0\t1\t0\t1\t1\t1\t0\t0\t0\t0\t0\t1\t1\t0\n",
      "0\t1\t0\t0\t0\t1\t1\t1\t0\t1\t1\t1\t1\t0\n",
      "1\t1\t1\t0\t1\t0\t0\t1\t0\t1\t1\t0\t1\t1\n",
      "1\t0\t0\t1\t0\t0\t1\t1\t0\t0\t1\t1\t1\t0\n",
      "0\t0\t0\t1\t0\t1\t1\t0\t1\t1\t1\t1\t1\t0\n",
      "1\t0\t1\t0\t1\t1\t0\t0\t0\t1\t0\t0\t1\t0\n",
      "0\t1\t1\t0\t1\t0\t1\t0\t1\t1\t1\t0\t1\t1\n",
      "0\t1\t0\t0\t1\t1\t1\t1\t1\t1\t0\t0\t1\t0\n",
      "1\t1\t0\t1\t0\t1\t1\t0\t1\t0\t0\t0\t1\t0\n",
      "1\t0\t1\t1\t0\t1\t0\t0\t0\t0\t1\t1\t1\t1\n",
      "1\t0\t1\t1\t1\t1\t0\t1\t1\t0\t1\t0\t1\t1\n",
      "1\t0\t0\t1\t0\t0\t0\t1\t0\t1\t0\t1\t1\t1\n",
      "1\t1\t0\t1\t1\t0\t1\t1\t0\t0\t1\t0\t1\t0\n",
      "0\t0\t0\t0\t1\t1\t1\t0\t0\t1\t0\t1\t1\t0\n",
      "1\t1\t1\t0\t0\t0\t1\t0\t0\t0\t1\t1\t1\t0\n",
      "1\t0\t1\t0\t0\t1\t0\t0\t0\t0\t1\t1\t1\t0\n",
      "1\t0\t1\t1\t1\t1\t0\t0\t0\t0\t1\t1\t1\t0\n",
      "0\t1\t0\t0\t1\t1\t1\t0\t1\t1\t0\t1\t1\t1\n",
      "0\t1\t1\t1\t0\t0\t1\t0\t1\t1\t1\t0\t1\t1\n",
      "1\t0\t0\t0\t0\t0\t0\t1\t1\t1\t1\t0\t1\t1\n",
      "1\t0\t1\t1\t0\t1\t1\t0\t0\t1\t0\t1\t1\t0\n",
      "1\t1\t1\t0\t1\t1\t0\t1\t1\t0\t1\t0\t1\t1\n",
      "0\t1\t0\t1\t0\t1\t0\t1\t0\t0\t0\t1\t1\t0\n",
      "1\t0\t0\t1\t0\t1\t0\t1\t1\t1\t0\t1\t1\t0\n",
      "0\t1\t1\t0\t1\t1\t0\t0\t0\t1\t1\t0\t1\t1\n",
      "1\t0\t1\t1\t0\t1\t1\t1\t0\t0\t1\t0\t1\t0\n",
      "1\t1\t0\t1\t1\t1\t0\t1\t1\t1\t1\t0\t1\t1\n",
      "1\t1\t0\t1\t0\t0\t1\t0\t1\t0\t1\t0\t1\t1\n",
      "1\t0\t1\t1\t0\t0\t0\t0\t0\t1\t0\t1\t1\t1\n",
      "1\t1\t1\t1\t1\t1\t1\t1\t1\t0\t1\t0\t1\t1\n",
      "1\t0\t0\t0\t0\t1\t0\t1\t1\t1\t1\t1\t1\t1\n",
      "1\t1\t0\t1\t1\t1\t1\t0\t0\t0\t0\t1\t1\t0\n",
      "0\t1\t0\t1\t0\t0\t1\t1\t0\t1\t0\t1\t1\t0\n",
      "0\t0\t0\t0\t0\t1\t0\t1\t0\t1\t1\t1\t1\t0\n",
      "1\t0\t0\t1\t0\t0\t1\t1\t1\t1\t1\t1\t1\t0\n",
      "0\t1\t1\t1\t0\t1\t0\t1\t1\t0\t1\t0\t1\t1\n",
      "1\t1\t1\t1\t0\t1\t1\t0\t0\t0\t1\t0\t1\t0\n",
      "0\t0\t0\t0\t0\t0\t1\t0\t0\t1\t0\t1\t1\t1\n",
      "0\t1\t1\t0\t1\t0\t0\t1\t0\t1\t0\t1\t1\t1\n",
      "0\t0\t1\t0\t0\t0\t1\t0\t1\t0\t1\t1\t1\t0\n",
      "0\t1\t1\t1\t1\t0\t1\t1\t0\t0\t0\t0\t1\t0\n",
      "0\t1\t0\t0\t0\t0\t1\t1\t1\t0\t1\t0\t1\t1\n",
      "1\t1\t0\t0\t0\t0\t1\t0\t1\t0\t1\t1\t1\t0\n",
      "0\t1\t1\t0\t1\t1\t1\t0\t1\t1\t1\t1\t1\t0\n",
      "1\t1\t1\t0\t1\t1\t1\t0\t1\t0\t0\t1\t1\t0\n",
      "0\t0\t1\t0\t0\t0\t1\t1\t1\t1\t0\t0\t1\t1\n",
      "1\t1\t1\t1\t1\t0\t0\t0\t1\t1\t1\t0\t1\t0\n",
      "1\t0\t1\t1\t0\t1\t1\t0\t0\t1\t0\t0\t1\t0\n",
      "0\t1\t0\t1\t1\t1\t1\t1\t1\t0\t0\t1\t1\t0\n",
      "1\t1\t1\t0\t0\t1\t1\t1\t0\t0\t1\t1\t1\t0\n",
      "1\t1\t1\t0\t1\t0\t1\t0\t0\t1\t1\t1\t1\t0\n",
      "0\t0\t0\t0\t0\t0\t0\t1\t1\t0\t1\t1\t1\t0\n",
      "1\t0\t0\t0\t1\t1\t1\t1\t0\t1\t0\t0\t1\t0\n",
      "1\t1\t1\t0\t0\t0\t1\t1\t1\t1\t0\t1\t1\t0\n",
      "0\t1\t1\t0\t0\t0\t1\t1\t0\t0\t1\t0\t1\t0\n",
      "0\t1\t1\t0\t1\t0\t1\t0\t0\t0\t0\t1\t1\t1\n",
      "1\t0\t0\t1\t0\t1\t1\t1\t1\t0\t1\t0\t1\t1\n",
      "1\t1\t0\t0\t0\t0\t0\t1\t0\t1\t1\t1\t1\t1\n",
      "1\t1\t1\t0\t0\t1\t1\t1\t0\t0\t0\t1\t1\t0\n",
      "0\t1\t0\t1\t1\t1\t0\t1\t1\t1\t1\t0\t1\t1\n",
      "0\t1\t1\t0\t1\t0\t1\t0\t0\t0\t1\t1\t1\t0\n",
      "0\t0\t0\t1\t1\t1\t1\t1\t1\t0\t0\t1\t1\t1\n",
      "1\t0\t1\t0\t1\t1\t1\t0\t1\t0\t1\t1\t1\t0\n",
      "0\t0\t0\t1\t0\t0\t0\t0\t1\t0\t1\t0\t1\t1\n",
      "0\t1\t0\t1\t0\t0\t0\t1\t0\t1\t0\t1\t1\t1\n",
      "1\t1\t0\t0\t0\t1\t0\t1\t1\t1\t0\t1\t1\t1\n",
      "1\t1\t1\t0\t0\t0\t1\t1\t0\t0\t1\t1\t1\t0\n",
      "1\t1\t1\t1\t1\t0\t1\t0\t0\t0\t1\t0\t1\t0\n",
      "1\t1\t1\t0\t0\t0\t1\t0\t0\t0\t1\t1\t1\t0\n",
      "1\t1\t0\t0\t1\t1\t1\t1\t0\t1\t0\t1\t1\t0\n",
      "0\t1\t1\t1\t0\t1\t1\t0\t0\t1\t1\t1\t1\t0\n",
      "1\t1\t1\t1\t1\t1\t1\t0\t0\t0\t1\t0\t1\t0\n",
      "0\t1\t1\t0\t0\t0\t1\t1\t1\t0\t1\t0\t1\t1\n",
      "0\t1\t0\t1\t0\t0\t0\t1\t0\t0\t1\t0\t1\t0\n",
      "1\t1\t1\t0\t1\t0\t1\t1\t1\t0\t1\t1\t1\t0\n",
      "1\t1\t0\t0\t0\t1\t0\t1\t0\t1\t1\t0\t1\t1\n",
      "0\t1\t0\t0\t0\t1\t0\t0\t0\t1\t1\t0\t1\t1\n",
      "1\t1\t1\t1\t0\t1\t0\t0\t1\t0\t0\t0\t1\t0\n",
      "0\t0\t1\t1\t1\t1\t0\t0\t0\t0\t0\t1\t1\t1\n",
      "0\t1\t1\t1\t1\t0\t0\t1\t0\t0\t0\t1\t1\t0\n",
      "1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t0\t1\t1\t0\n",
      "1\t1\t1\t0\t1\t0\t0\t1\t0\t0\t1\t1\t1\t0\n",
      "1\t0\t1\t0\t1\t1\t1\t1\t0\t0\t1\t1\t1\t0\n",
      "0\t1\t0\t1\t0\t1\t1\t0\t0\t1\t1\t0\t1\t0\n",
      "1\t0\t0\t1\t0\t0\t0\t1\t1\t0\t1\t1\t1\t0\n",
      "1\t1\t1\t0\t1\t1\t1\t0\t0\t0\t1\t0\t1\t0\n",
      "1\t1\t1\t1\t0\t0\t0\t1\t1\t1\t1\t1\t1\t0\n",
      "1\t0\t1\t1\t0\t1\t1\t1\t0\t1\t1\t0\t1\t0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100  2844  100  2844    0     0  95177      0 --:--:-- --:--:-- --:--:--   99k\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A1\tA2\tA3\tA4\tA5\tA6\tA7\tA8\tA9\tA10\tA11\tA12\tA13\t\n",
      "1\t1\t0\t0\t0\t0\t0\t0\t1\t1\t0\t0\t1\t0\n",
      "0\t0\t1\t1\t0\t1\t1\t0\t0\t0\t0\t0\t1\t0\n",
      "0\t1\t0\t1\t1\t0\t1\t0\t1\t1\t1\t0\t1\t1\n",
      "0\t0\t1\t0\t0\t1\t0\t1\t0\t1\t1\t1\t1\t0\n",
      "0\t1\t0\t0\t0\t0\t0\t1\t1\t1\t1\t1\t1\t0\n",
      "0\t1\t1\t1\t0\t0\t0\t1\t0\t1\t1\t0\t1\t1\n",
      "0\t1\t1\t0\t0\t0\t1\t0\t0\t0\t0\t0\t1\t0\n",
      "0\t0\t0\t1\t1\t0\t1\t1\t1\t0\t0\t0\t1\t0\n",
      "0\t0\t0\t0\t0\t0\t1\t0\t1\t0\t1\t0\t1\t0\n",
      "1\t0\t1\t1\t1\t0\t0\t0\t1\t1\t1\t0\t1\t1\n",
      "0\t1\t1\t0\t1\t0\t1\t1\t1\t1\t1\t1\t1\t1\n",
      "0\t0\t1\t1\t0\t0\t1\t0\t0\t1\t1\t1\t1\t0\n",
      "1\t0\t1\t1\t0\t0\t1\t1\t0\t1\t0\t0\t1\t1\n",
      "0\t0\t1\t1\t0\t0\t0\t0\t1\t0\t1\t1\t1\t0\n",
      "1\t0\t0\t0\t0\t0\t1\t0\t1\t1\t0\t1\t1\t0\n",
      "0\t1\t1\t1\t1\t1\t0\t0\t1\t0\t1\t0\t1\t1\n",
      "1\t0\t0\t0\t1\t0\t1\t1\t1\t1\t1\t1\t1\t0\n",
      "1\t0\t0\t0\t0\t1\t1\t0\t1\t1\t1\t1\t1\t0\n",
      "1\t0\t0\t1\t0\t1\t0\t1\t1\t0\t0\t1\t1\t0\n",
      "0\t0\t1\t1\t0\t1\t1\t0\t0\t0\t0\t1\t1\t0\n",
      "1\t1\t1\t0\t0\t1\t1\t1\t1\t1\t0\t1\t1\t1\n",
      "0\t1\t1\t1\t1\t1\t0\t0\t0\t1\t0\t1\t1\t0\n",
      "0\t0\t1\t1\t0\t1\t0\t1\t0\t1\t1\t1\t1\t0\n",
      "1\t0\t0\t1\t0\t1\t1\t1\t1\t0\t0\t1\t1\t0\n",
      "0\t0\t1\t0\t0\t0\t1\t0\t0\t0\t0\t0\t1\t0\n",
      "1\t0\t1\t0\t0\t0\t1\t1\t0\t0\t0\t1\t1\t0\n",
      "1\t0\t0\t0\t0\t1\t0\t0\t0\t1\t0\t1\t1\t0\n",
      "1\t0\t0\t0\t1\t1\t1\t0\t0\t1\t0\t1\t1\t0\n",
      "1\t0\t0\t0\t0\t0\t1\t1\t1\t1\t1\t0\t1\t0\n",
      "0\t0\t1\t1\t0\t1\t0\t1\t0\t0\t1\t0\t1\t0\n",
      "0\t1\t1\t0\t0\t0\t1\t1\t1\t1\t0\t1\t1\t0\n",
      "0\t0\t0\t0\t1\t1\t1\t1\t0\t0\t0\t0\t1\t0\n",
      "0\t1\t1\t0\t1\t1\t1\t1\t0\t0\t0\t1\t1\t0\n",
      "0\t1\t0\t1\t0\t0\t0\t1\t0\t0\t0\t1\t1\t0\n",
      "1\t0\t0\t1\t0\t0\t1\t1\t1\t1\t0\t0\t1\t0\n",
      "0\t0\t0\t1\t0\t1\t1\t1\t1\t1\t1\t1\t1\t0\n",
      "1\t1\t0\t1\t0\t1\t1\t0\t0\t0\t1\t1\t1\t0\n",
      "0\t0\t0\t0\t1\t0\t0\t1\t1\t1\t0\t0\t1\t0\n",
      "0\t1\t1\t1\t0\t0\t1\t1\t1\t1\t1\t1\t1\t0\n",
      "0\t0\t0\t0\t1\t0\t0\t0\t0\t0\t0\t0\t1\t0\n",
      "1\t0\t1\t0\t1\t0\t1\t1\t1\t1\t0\t0\t1\t0\n",
      "1\t1\t1\t1\t1\t0\t1\t0\t0\t0\t0\t0\t1\t0\n",
      "1\t1\t1\t0\t1\t0\t1\t0\t1\t1\t1\t0\t1\t1\n",
      "1\t0\t1\t1\t1\t1\t1\t1\t0\t1\t1\t1\t1\t0\n",
      "0\t1\t1\t0\t1\t0\t0\t0\t1\t0\t0\t0\t1\t0\n",
      "0\t0\t1\t1\t1\t0\t0\t0\t0\t1\t0\t0\t1\t0\n",
      "0\t1\t1\t0\t0\t1\t1\t0\t0\t0\t0\t1\t1\t0\n",
      "0\t0\t1\t0\t1\t0\t0\t0\t0\t0\t0\t1\t1\t1\n",
      "1\t0\t0\t1\t0\t1\t0\t0\t0\t1\t1\t1\t1\t0\n",
      "1\t1\t1\t1\t1\t1\t0\t1\t1\t0\t0\t1\t1\t0\n",
      "0\t1\t0\t1\t1\t0\t0\t0\t1\t0\t0\t0\t1\t0\n",
      "0\t1\t1\t0\t1\t0\t0\t1\t0\t0\t0\t0\t1\t0\n",
      "0\t0\t0\t0\t0\t1\t0\t1\t0\t1\t1\t1\t1\t1\n",
      "0\t1\t0\t0\t1\t1\t1\t0\t1\t0\t1\t1\t1\t0\n",
      "0\t0\t0\t0\t1\t1\t1\t1\t1\t1\t1\t0\t1\t0\n",
      "0\t0\t1\t1\t1\t1\t1\t0\t1\t0\t1\t1\t1\t0\n",
      "0\t1\t0\t0\t0\t0\t1\t0\t0\t1\t0\t1\t1\t0\n",
      "0\t0\t1\t0\t1\t1\t0\t0\t0\t1\t1\t0\t1\t0\n",
      "1\t0\t1\t0\t1\t0\t0\t0\t1\t0\t0\t1\t1\t1\n",
      "0\t0\t0\t1\t0\t1\t0\t0\t1\t1\t1\t0\t1\t1\n",
      "0\t1\t0\t0\t1\t0\t1\t1\t0\t0\t1\t1\t1\t0\n",
      "0\t0\t1\t0\t1\t1\t1\t0\t0\t1\t1\t1\t1\t0\n",
      "1\t1\t1\t0\t0\t0\t1\t1\t1\t1\t1\t0\t1\t0\n",
      "1\t0\t1\t0\t0\t0\t0\t1\t1\t1\t1\t0\t1\t1\n",
      "0\t1\t0\t1\t1\t1\t0\t0\t1\t0\t0\t0\t1\t0\n",
      "0\t1\t1\t1\t0\t0\t1\t0\t0\t1\t1\t0\t1\t1\n",
      "0\t1\t0\t1\t0\t1\t1\t1\t0\t0\t0\t0\t1\t0\n",
      "1\t0\t1\t0\t1\t0\t0\t0\t0\t1\t0\t1\t1\t0\n",
      "1\t1\t0\t0\t1\t1\t1\t0\t0\t1\t1\t1\t1\t1\n",
      "1\t0\t1\t0\t1\t0\t1\t1\t0\t1\t1\t0\t1\t0\n",
      "1\t1\t0\t1\t0\t0\t0\t0\t0\t1\t1\t1\t1\t0\n",
      "1\t1\t1\t0\t0\t1\t0\t0\t0\t1\t0\t0\t1\t0\n",
      "1\t0\t1\t1\t1\t0\t0\t0\t1\t0\t1\t0\t1\t1\n",
      "1\t1\t0\t0\t1\t0\t1\t1\t1\t0\t0\t0\t1\t0\n",
      "1\t0\t1\t0\t1\t1\t1\t0\t1\t1\t0\t0\t1\t0\n",
      "0\t0\t1\t0\t1\t1\t1\t1\t1\t1\t0\t0\t1\t0\n",
      "0\t0\t1\t0\t1\t1\t0\t1\t1\t1\t0\t0\t1\t0\n",
      "1\t0\t0\t1\t1\t1\t0\t1\t0\t0\t0\t0\t1\t0\n",
      "1\t0\t1\t1\t1\t0\t1\t0\t1\t0\t1\t1\t1\t0\n",
      "0\t0\t0\t0\t1\t1\t0\t0\t0\t1\t1\t1\t1\t0\n",
      "0\t1\t1\t0\t0\t0\t1\t0\t1\t1\t1\t0\t1\t1\n",
      "1\t1\t0\t0\t1\t0\t1\t0\t0\t1\t0\t0\t1\t0\n",
      "1\t0\t0\t0\t1\t1\t0\t0\t1\t1\t0\t0\t1\t0\n",
      "0\t1\t0\t1\t1\t1\t0\t0\t0\t0\t1\t0\t1\t0\n",
      "0\t1\t1\t0\t1\t1\t1\t0\t0\t0\t0\t1\t1\t0\n",
      "0\t1\t0\t1\t1\t0\t1\t0\t0\t0\t1\t1\t1\t0\n",
      "1\t1\t0\t1\t0\t1\t0\t1\t0\t0\t0\t1\t1\t0\n",
      "1\t1\t1\t0\t0\t1\t0\t1\t0\t1\t0\t0\t1\t0\n",
      "1\t1\t0\t0\t1\t0\t1\t0\t1\t0\t0\t1\t1\t0\n",
      "1\t0\t0\t0\t0\t1\t0\t1\t1\t0\t1\t0\t1\t1\n",
      "1\t0\t1\t1\t0\t1\t0\t1\t1\t1\t1\t1\t1\t0\n",
      "1\t1\t1\t1\t0\t1\t0\t1\t0\t1\t1\t1\t1\t1\n",
      "0\t0\t0\t0\t1\t1\t1\t1\t1\t1\t0\t0\t1\t0\n",
      "0\t0\t0\t0\t1\t1\t1\t1\t1\t0\t0\t0\t1\t1\n",
      "1\t0\t0\t1\t0\t0\t1\t1\t0\t0\t0\t1\t1\t0\n",
      "1\t1\t0\t1\t0\t0\t1\t1\t0\t1\t1\t0\t1\t1\n",
      "1\t1\t1\t0\t0\t0\t0\t1\t1\t0\t1\t0\t1\t1\n",
      "0\t0\t0\t0\t0\t1\t1\t1\t0\t0\t1\t0\t1\t0\n",
      "0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t1\t1\t0\n",
      "0\t1\t1\t1\t0\t0\t0\t0\t1\t1\t1\t0\t1\t1\n",
      "0\t1\t0\t0\t1\t0\t0\t1\t1\t1\t0\t0\t1\t0\n",
      "1\t1\t1\t0\t1\t1\t0\t1\t0\t1\t1\t0\t1\t1\n",
      "0\t1\t1\t1\t0\t0\t1\t1\t0\t0\t1\t1\t1\t0\n",
      "1\t1\t0\t0\t1\t1\t0\t0\t0\t1\t1\t0\t1\t1\n",
      "0\t0\t0\t0\t0\t0\t1\t1\t0\t0\t0\t0\t1\t0\n",
      "1\t1\t1\t1\t1\t0\t0\t0\t0\t1\t0\t1\t1\t0\n",
      "0\t1\t0\t1\t1\t0\t0\t0\t0\t0\t1\t1\t1\t0\n",
      "0\t0\t0\t0\t1\t0\t0\t0\t0\t0\t1\t0\t1\t0\n",
      "0\t1\t1\t1\t1\t1\t1\t1\t0\t1\t1\t1\t1\t0\n",
      "1\t0\t0\t1\t1\t0\t1\t1\t1\t0\t0\t1\t1\t0\n",
      "0\t1\t0\t0\t0\t1\t1\t1\t1\t0\t0\t0\t1\t0\n",
      "0\t1\t0\t0\t0\t1\t0\t0\t0\t1\t1\t1\t1\t0\n",
      "0\t0\t0\t0\t1\t1\t1\t1\t0\t1\t0\t0\t1\t0\n",
      "1\t0\t1\t0\t1\t0\t0\t1\t1\t0\t0\t1\t1\t0\n",
      "1\t0\t1\t0\t1\t0\t0\t0\t1\t1\t0\t0\t1\t0\n",
      "0\t0\t0\t1\t0\t0\t0\t1\t0\t1\t1\t0\t1\t1\n",
      "0\t0\t0\t1\t1\t1\t1\t1\t0\t1\t0\t0\t1\t0\n",
      "1\t1\t1\t0\t0\t1\t0\t0\t0\t1\t0\t1\t1\t0\n",
      "1\t1\t0\t0\t0\t0\t0\t1\t1\t0\t1\t1\t1\t0\n",
      "1\t1\t1\t1\t1\t0\t0\t0\t1\t0\t1\t0\t1\t1\n",
      "0\t0\t1\t0\t1\t1\t0\t1\t0\t1\t0\t1\t1\t1\n",
      "0\t1\t0\t0\t1\t0\t0\t0\t1\t0\t0\t0\t1\t0\n",
      "0\t1\t0\t1\t0\t1\t1\t0\t0\t1\t0\t1\t1\t0\n",
      "1\t1\t1\t1\t1\t0\t1\t1\t0\t0\t0\t1\t1\t0\n",
      "1\t0\t1\t1\t1\t1\t1\t0\t0\t0\t0\t0\t1\t0\n",
      "0\t1\t0\t1\t0\t1\t0\t1\t1\t0\t0\t1\t1\t0\n",
      "1\t0\t0\t1\t1\t0\t1\t1\t0\t0\t1\t1\t1\t0\n",
      "0\t0\t1\t0\t1\t1\t0\t1\t1\t1\t1\t1\t1\t0\n",
      "1\t0\t0\t1\t1\t1\t1\t1\t1\t0\t0\t1\t1\t0\n",
      "0\t1\t0\t0\t1\t1\t1\t1\t1\t1\t0\t1\t1\t1\n",
      "1\t1\t1\t1\t0\t0\t0\t1\t0\t0\t1\t1\t1\t0\n",
      "0\t1\t1\t1\t1\t0\t1\t0\t1\t1\t1\t1\t1\t1\n",
      "0\t0\t0\t0\t1\t1\t1\t1\t1\t1\t1\t0\t1\t0\n",
      "1\t1\t0\t0\t1\t1\t0\t0\t0\t1\t0\t1\t1\t0\n",
      "1\t0\t1\t1\t0\t1\t1\t0\t1\t0\t0\t0\t1\t0\n",
      "0\t1\t0\t1\t1\t1\t0\t1\t1\t1\t1\t0\t1\t0\n",
      "0\t1\t1\t0\t1\t1\t0\t0\t0\t0\t1\t1\t1\t0\n",
      "1\t1\t0\t1\t1\t1\t0\t1\t1\t0\t1\t0\t1\t1\n",
      "0\t1\t0\t0\t1\t1\t1\t0\t1\t0\t1\t0\t1\t1\n",
      "0\t0\t1\t1\t1\t1\t0\t0\t0\t1\t1\t1\t1\t0\n",
      "1\t1\t0\t1\t0\t1\t1\t0\t0\t0\t0\t1\t1\t1\n",
      "1\t1\t1\t1\t1\t0\t0\t0\t1\t0\t0\t0\t1\t1\n",
      "0\t1\t0\t1\t1\t1\t0\t1\t0\t1\t1\t1\t1\t1\n",
      "1\t0\t1\t1\t1\t0\t1\t1\t0\t0\t0\t1\t1\t0\n",
      "1\t0\t0\t0\t0\t1\t0\t0\t0\t1\t1\t0\t1\t1\n",
      "1\t1\t1\t1\t0\t0\t1\t1\t1\t1\t0\t0\t1\t1\n",
      "1\t0\t0\t1\t1\t1\t0\t1\t1\t0\t1\t0\t1\t1\n",
      "1\t0\t0\t1\t1\t0\t0\t1\t0\t0\t0\t1\t1\t0\n",
      "1\t0\t1\t0\t1\t1\t1\t0\t1\t0\t1\t1\t1\t0\n",
      "1\t1\t0\t1\t1\t1\t1\t0\t1\t1\t1\t1\t1\t1\n",
      "0\t1\t0\t1\t0\t0\t0\t0\t1\t0\t1\t0\t1\t1\n",
      "1\t0\t0\t1\t1\t0\t0\t0\t0\t1\t0\t0\t1\t0\n",
      "0\t1\t1\t0\t1\t1\t1\t1\t1\t0\t0\t1\t1\t0\n",
      "0\t0\t0\t1\t1\t0\t0\t0\t1\t1\t0\t1\t1\t0\n",
      "1\t1\t1\t1\t1\t0\t1\t0\t1\t1\t1\t0\t1\t1\n",
      "0\t0\t1\t0\t0\t1\t0\t1\t1\t1\t0\t1\t1\t1\n",
      "1\t1\t1\t0\t0\t1\t1\t1\t0\t0\t0\t1\t1\t1\n",
      "0\t0\t0\t0\t1\t1\t0\t0\t0\t1\t0\t1\t1\t0\n",
      "1\t1\t0\t0\t0\t1\t0\t1\t0\t1\t1\t0\t1\t0\n",
      "1\t1\t1\t1\t0\t0\t1\t1\t0\t0\t1\t1\t1\t0\n",
      "0\t1\t1\t0\t1\t1\t1\t1\t1\t1\t0\t1\t1\t0\n",
      "0\t0\t1\t1\t0\t1\t1\t1\t1\t0\t0\t0\t1\t0\n",
      "1\t0\t0\t1\t1\t0\t1\t1\t1\t0\t0\t0\t1\t1\n",
      "0\t0\t0\t0\t0\t0\t0\t0\t1\t1\t0\t1\t1\t0\n",
      "1\t1\t0\t0\t0\t1\t0\t0\t1\t1\t1\t1\t1\t1\n",
      "1\t0\t1\t0\t0\t0\t1\t1\t0\t1\t1\t1\t1\t0\n",
      "0\t0\t0\t0\t0\t1\t0\t1\t1\t1\t0\t0\t1\t0\n",
      "0\t1\t0\t0\t0\t0\t0\t1\t0\t1\t1\t0\t1\t1\n",
      "0\t1\t1\t0\t1\t0\t1\t0\t0\t1\t0\t1\t1\t0\n",
      "0\t0\t1\t0\t1\t1\t0\t0\t0\t0\t1\t0\t1\t0\n",
      "0\t0\t0\t0\t0\t1\t1\t1\t1\t0\t0\t1\t1\t0\n",
      "0\t1\t0\t0\t1\t1\t0\t1\t1\t0\t0\t0\t1\t0\n",
      "0\t1\t1\t1\t0\t1\t1\t1\t0\t1\t1\t0\t1\t0\n",
      "1\t1\t0\t0\t0\t0\t1\t1\t0\t1\t1\t1\t1\t0\n",
      "1\t0\t1\t0\t1\t0\t0\t1\t0\t1\t1\t1\t1\t1\n",
      "1\t1\t0\t0\t0\t1\t0\t1\t1\t0\t1\t0\t1\t1\n",
      "1\t0\t0\t1\t0\t0\t0\t1\t1\t1\t0\t0\t1\t0\n",
      "0\t1\t0\t0\t0\t0\t1\t0\t1\t0\t1\t1\t1\t0\n",
      "1\t1\t1\t0\t1\t0\t0\t0\t0\t0\t0\t0\t1\t0\n",
      "1\t0\t0\t1\t0\t1\t0\t0\t0\t1\t1\t1\t1\t0\n",
      "1\t0\t1\t1\t1\t1\t1\t1\t0\t0\t1\t0\t1\t0\n",
      "0\t1\t0\t1\t1\t0\t1\t1\t1\t1\t1\t0\t1\t0\n",
      "0\t0\t0\t1\t1\t0\t0\t0\t1\t1\t0\t1\t1\t0\n",
      "0\t0\t0\t1\t0\t0\t0\t0\t1\t0\t1\t0\t1\t1\n",
      "1\t1\t0\t1\t1\t0\t1\t0\t1\t1\t0\t0\t1\t0\n",
      "1\t1\t1\t1\t1\t1\t0\t0\t0\t1\t1\t0\t1\t1\n",
      "1\t0\t1\t1\t1\t0\t0\t1\t0\t0\t0\t1\t1\t1\n",
      "1\t1\t0\t1\t1\t0\t0\t0\t0\t0\t1\t1\t1\t0\n",
      "1\t1\t0\t0\t0\t1\t1\t0\t1\t1\t1\t1\t1\t0\n",
      "0\t0\t1\t0\t1\t0\t0\t1\t0\t0\t1\t1\t1\t1\n",
      "1\t1\t0\t0\t1\t0\t1\t1\t0\t1\t0\t1\t1\t0\n",
      "0\t0\t0\t0\t1\t0\t0\t0\t0\t0\t0\t1\t1\t0\n",
      "1\t0\t0\t1\t1\t0\t1\t0\t1\t0\t0\t1\t1\t0\n",
      "1\t0\t0\t0\t0\t1\t0\t0\t1\t0\t0\t1\t1\t0\n",
      "0\t0\t1\t1\t1\t0\t0\t1\t1\t1\t0\t1\t1\t1\n",
      "1\t1\t1\t1\t0\t1\t0\t0\t0\t0\t0\t1\t1\t0\n",
      "1\t1\t1\t0\t1\t1\t1\t1\t0\t1\t1\t1\t1\t0\n",
      "1\t1\t1\t1\t1\t1\t0\t1\t0\t1\t1\t0\t1\t1\n",
      "1\t1\t1\t0\t0\t0\t1\t0\t1\t0\t0\t0\t1\t0\n",
      "0\t0\t0\t1\t0\t0\t0\t0\t0\t1\t0\t1\t1\t1\n",
      "1\t1\t1\t0\t0\t1\t0\t1\t1\t0\t1\t0\t1\t1\n",
      "1\t1\t1\t1\t1\t1\t1\t0\t1\t1\t0\t0\t1\t0\n",
      "1\t0\t0\t1\t0\t1\t1\t1\t0\t1\t1\t1\t1\t0\n",
      "1\t0\t1\t1\t1\t0\t1\t1\t0\t0\t0\t0\t1\t0\n",
      "1\t1\t0\t0\t1\t1\t1\t0\t1\t1\t0\t0\t1\t0\n",
      "0\t1\t0\t1\t0\t1\t0\t1\t1\t1\t0\t0\t1\t0\n",
      "1\t0\t1\t1\t0\t0\t0\t0\t1\t1\t1\t0\t1\t1\n",
      "1\t1\t1\t1\t1\t1\t0\t1\t0\t0\t1\t1\t1\t0\n",
      "0\t1\t0\t0\t1\t0\t1\t1\t1\t0\t1\t0\t1\t1\n",
      "0\t0\t0\t1\t0\t1\t0\t0\t1\t0\t0\t0\t1\t0\n",
      "0\t1\t0\t0\t1\t1\t0\t0\t0\t1\t1\t0\t1\t1\n",
      "0\t1\t0\t0\t1\t0\t1\t1\t1\t1\t0\t0\t1\t0\n",
      "0\t1\t0\t0\t1\t0\t0\t0\t1\t1\t0\t1\t1\t0\n",
      "0\t0\t1\t1\t1\t1\t1\t0\t0\t0\t0\t1\t1\t0\n",
      "0\t1\t0\t1\t0\t0\t1\t0\t0\t1\t0\t0\t1\t0\n",
      "0\t1\t1\t0\t0\t1\t1\t0\t0\t1\t1\t1\t1\t0\n",
      "0\t1\t0\t1\t0\t0\t1\t0\t0\t0\t0\t0\t1\t0\n",
      "0\t1\t0\t1\t0\t1\t0\t0\t0\t0\t1\t0\t1\t0\n",
      "1\t1\t1\t0\t1\t1\t0\t0\t1\t0\t1\t0\t1\t1\n",
      "0\t0\t1\t0\t0\t0\t0\t1\t1\t1\t0\t1\t1\t1\n",
      "0\t1\t1\t0\t1\t1\t1\t0\t1\t0\t1\t1\t1\t0\n",
      "1\t1\t0\t0\t0\t1\t0\t1\t0\t1\t1\t0\t1\t1\n",
      "1\t1\t1\t0\t0\t0\t1\t1\t1\t1\t1\t0\t1\t0\n",
      "0\t1\t1\t0\t1\t0\t0\t0\t1\t1\t1\t0\t1\t1\n",
      "0\t1\t1\t1\t1\t1\t0\t0\t0\t1\t0\t0\t1\t0\n",
      "1\t0\t0\t0\t1\t0\t1\t1\t0\t1\t0\t0\t1\t0\n",
      "0\t0\t1\t0\t1\t1\t0\t1\t0\t1\t0\t1\t1\t0\n",
      "1\t0\t1\t1\t1\t0\t0\t0\t0\t0\t1\t1\t1\t0\n",
      "0\t0\t0\t0\t1\t1\t1\t0\t1\t0\t1\t0\t1\t1\n",
      "1\t1\t0\t1\t1\t1\t1\t0\t0\t1\t0\t0\t1\t0\n",
      "0\t0\t0\t0\t1\t1\t0\t0\t1\t0\t0\t0\t1\t0\n",
      "0\t0\t0\t1\t1\t0\t0\t1\t1\t1\t0\t1\t1\t1\n",
      "0\t0\t1\t0\t1\t1\t0\t0\t1\t1\t1\t1\t1\t1\n",
      "0\t0\t1\t1\t1\t1\t0\t1\t0\t1\t1\t0\t1\t1\n",
      "0\t0\t0\t1\t0\t0\t0\t0\t0\t0\t0\t1\t1\t0\n",
      "0\t0\t1\t1\t1\t1\t0\t0\t0\t1\t0\t1\t1\t0\n",
      "0\t0\t0\t1\t1\t1\t1\t1\t1\t0\t0\t1\t1\t0\n",
      "1\t0\t0\t1\t0\t1\t1\t0\t0\t0\t1\t0\t1\t0\n",
      "1\t0\t1\t1\t1\t1\t1\t0\t0\t0\t0\t0\t1\t0\n",
      "1\t1\t1\t0\t0\t1\t0\t1\t1\t1\t1\t0\t1\t1\n",
      "1\t1\t1\t0\t0\t1\t1\t0\t1\t0\t1\t0\t1\t1\n",
      "0\t1\t1\t0\t0\t0\t0\t1\t0\t1\t0\t0\t1\t0\n",
      "1\t1\t0\t0\t1\t0\t1\t0\t0\t0\t0\t0\t1\t0\n",
      "0\t0\t1\t0\t0\t1\t0\t0\t0\t0\t0\t0\t1\t0\n",
      "0\t1\t1\t1\t1\t1\t0\t0\t0\t0\t1\t0\t1\t0\n",
      "1\t1\t0\t1\t0\t0\t0\t0\t0\t1\t0\t0\t1\t1\n",
      "1\t0\t0\t1\t1\t0\t1\t1\t0\t1\t0\t1\t1\t0\n",
      "0\t1\t1\t1\t1\t0\t0\t1\t0\t0\t1\t0\t1\t0\n",
      "1\t0\t0\t1\t1\t1\t0\t0\t0\t1\t0\t0\t1\t0\n",
      "0\t1\t0\t0\t0\t1\t1\t1\t1\t0\t0\t1\t1\t0\n",
      "0\t1\t1\t0\t0\t1\t0\t1\t1\t0\t1\t0\t1\t1\n",
      "0\t1\t1\t0\t0\t1\t0\t0\t1\t0\t0\t1\t1\t0\n",
      "0\t1\t1\t0\t0\t1\t1\t0\t0\t0\t1\t1\t1\t0\n",
      "1\t0\t0\t0\t0\t0\t1\t0\t0\t1\t1\t0\t1\t0\n",
      "1\t0\t1\t1\t0\t1\t0\t1\t0\t0\t1\t1\t1\t1\n",
      "0\t1\t1\t0\t0\t0\t0\t1\t0\t0\t1\t1\t1\t0\n",
      "1\t1\t1\t0\t0\t0\t1\t0\t1\t1\t0\t1\t1\t0\n",
      "0\t0\t0\t1\t0\t0\t0\t0\t1\t0\t0\t1\t1\t0\n",
      "1\t0\t0\t0\t1\t1\t1\t0\t1\t0\t1\t0\t1\t1\n",
      "0\t1\t0\t1\t0\t1\t0\t0\t0\t1\t1\t1\t1\t0\n",
      "0\t1\t0\t0\t0\t0\t1\t0\t1\t0\t0\t0\t1\t0\n",
      "1\t1\t1\t0\t1\t0\t0\t1\t1\t0\t1\t1\t1\t0\n",
      "0\t1\t0\t0\t1\t1\t1\t1\t0\t1\t1\t0\t1\t0\n",
      "1\t1\t0\t0\t1\t0\t1\t1\t1\t1\t1\t1\t1\t0\n",
      "1\t1\t0\t0\t1\t1\t1\t0\t1\t1\t0\t1\t1\t0\n",
      "0\t0\t1\t1\t0\t0\t0\t0\t0\t1\t0\t0\t1\t0\n",
      "1\t0\t1\t1\t0\t0\t1\t0\t1\t0\t1\t0\t1\t1\n",
      "0\t0\t0\t1\t1\t0\t1\t1\t0\t1\t1\t1\t1\t1\n",
      "1\t0\t1\t1\t0\t0\t0\t1\t0\t1\t0\t1\t1\t1\n",
      "0\t1\t1\t0\t0\t0\t1\t0\t0\t0\t1\t0\t1\t1\n",
      "1\t0\t0\t0\t1\t1\t1\t1\t1\t0\t1\t1\t1\t0\n",
      "1\t1\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t1\t0\n",
      "0\t1\t1\t1\t1\t1\t1\t1\t1\t1\t0\t0\t1\t1\n",
      "0\t1\t0\t1\t1\t0\t1\t1\t1\t0\t0\t1\t1\t0\n",
      "1\t0\t0\t1\t0\t0\t0\t1\t1\t1\t0\t0\t1\t0\n",
      "0\t1\t0\t1\t1\t1\t1\t1\t0\t1\t0\t0\t1\t0\n",
      "0\t0\t1\t0\t1\t1\t1\t0\t1\t0\t0\t1\t1\t1\n",
      "1\t1\t0\t0\t1\t0\t0\t1\t0\t0\t0\t0\t1\t0\n",
      "1\t0\t0\t1\t0\t0\t1\t1\t0\t1\t0\t0\t1\t1\n",
      "0\t0\t0\t1\t1\t0\t0\t0\t0\t1\t0\t1\t1\t0\n",
      "1\t0\t1\t0\t1\t1\t0\t1\t0\t1\t1\t0\t1\t1\n",
      "0\t1\t1\t1\t0\t0\t1\t0\t0\t1\t1\t1\t1\t0\n",
      "0\t1\t0\t0\t1\t1\t0\t0\t0\t0\t1\t0\t1\t0\n",
      "1\t0\t0\t0\t0\t0\t1\t1\t1\t1\t0\t0\t1\t0\n",
      "1\t1\t1\t1\t0\t0\t0\t1\t1\t1\t0\t0\t1\t1\n",
      "0\t1\t1\t1\t0\t0\t0\t1\t1\t0\t0\t0\t1\t0\n",
      "0\t0\t1\t0\t1\t0\t0\t1\t1\t1\t1\t1\t1\t0\n",
      "0\t1\t1\t1\t0\t1\t0\t0\t1\t1\t1\t0\t1\t1\n",
      "0\t0\t1\t1\t0\t0\t1\t0\t1\t0\t1\t1\t1\t0\n",
      "0\t0\t1\t1\t0\t0\t0\t0\t0\t0\t1\t0\t1\t0\n",
      "0\t1\t1\t1\t1\t0\t0\t0\t1\t1\t1\t0\t1\t1\n",
      "0\t0\t1\t0\t1\t1\t1\t1\t0\t0\t0\t0\t1\t0\n",
      "0\t0\t1\t1\t0\t0\t0\t0\t1\t1\t0\t0\t1\t0\n",
      "0\t0\t1\t0\t0\t0\t1\t0\t1\t1\t0\t0\t1\t0\n",
      "1\t1\t1\t0\t1\t0\t1\t0\t0\t1\t0\t0\t1\t0\n",
      "1\t1\t0\t0\t1\t0\t1\t0\t1\t0\t0\t1\t1\t0\n",
      "0\t1\t1\t0\t1\t1\t0\t1\t1\t0\t0\t0\t1\t0\n",
      "0\t1\t1\t1\t0\t1\t1\t1\t0\t1\t1\t1\t1\t0\n",
      "1\t0\t1\t1\t0\t1\t0\t1\t1\t1\t1\t1\t1\t0\n",
      "1\t1\t1\t0\t1\t0\t1\t1\t1\t0\t1\t0\t1\t1\n",
      "1\t0\t1\t0\t1\t0\t1\t1\t0\t0\t0\t0\t1\t0\n",
      "0\t1\t1\t0\t1\t1\t0\t0\t1\t0\t0\t0\t1\t0\n",
      "0\t1\t0\t1\t0\t1\t1\t0\t0\t0\t1\t0\t1\t0\n",
      "1\t0\t1\t0\t0\t1\t1\t1\t1\t1\t0\t0\t1\t1\n",
      "0\t1\t1\t1\t1\t0\t0\t0\t0\t0\t0\t1\t1\t0\n",
      "0\t0\t1\t0\t1\t0\t1\t0\t1\t1\t0\t0\t1\t0\n",
      "1\t0\t1\t1\t0\t0\t0\t1\t0\t1\t0\t1\t1\t1\n",
      "1\t0\t0\t1\t0\t1\t1\t1\t1\t1\t0\t1\t1\t1\n",
      "1\t1\t0\t0\t1\t0\t1\t0\t1\t1\t1\t1\t1\t0\n",
      "0\t0\t1\t1\t1\t0\t1\t1\t1\t0\t0\t0\t1\t0\n",
      "1\t0\t1\t1\t0\t0\t1\t0\t0\t1\t1\t1\t1\t0\n",
      "0\t0\t1\t1\t0\t0\t1\t0\t0\t0\t0\t0\t1\t0\n",
      "1\t1\t1\t1\t1\t0\t0\t1\t0\t0\t0\t0\t1\t0\n",
      "0\t1\t1\t0\t1\t1\t0\t0\t0\t1\t0\t1\t1\t0\n",
      "1\t1\t0\t0\t0\t1\t0\t1\t0\t0\t0\t0\t1\t0\n",
      "0\t0\t0\t1\t1\t1\t1\t0\t1\t0\t0\t0\t1\t0\n",
      "0\t0\t0\t0\t1\t1\t1\t0\t1\t0\t0\t1\t1\t0\n",
      "0\t1\t1\t0\t0\t0\t0\t1\t1\t1\t0\t0\t1\t0\n",
      "1\t1\t0\t0\t1\t0\t1\t0\t0\t1\t0\t0\t1\t0\n",
      "1\t0\t0\t1\t0\t1\t1\t1\t1\t1\t1\t1\t1\t0\n",
      "1\t0\t1\t0\t0\t1\t1\t0\t1\t1\t0\t0\t1\t0\n",
      "0\t0\t0\t0\t1\t1\t0\t1\t0\t1\t1\t0\t1\t1\n",
      "0\t0\t1\t0\t1\t0\t1\t1\t0\t1\t1\t0\t1\t0\n",
      "1\t0\t1\t1\t1\t0\t0\t0\t0\t1\t1\t0\t1\t0\n",
      "0\t1\t1\t1\t0\t1\t0\t1\t0\t0\t1\t0\t1\t0\n",
      "1\t0\t1\t1\t1\t0\t1\t0\t1\t1\t0\t1\t1\t1\n",
      "1\t1\t1\t1\t0\t0\t0\t1\t0\t0\t0\t1\t1\t0\n",
      "0\t0\t0\t1\t1\t1\t1\t1\t1\t0\t1\t0\t1\t1\n",
      "1\t0\t1\t1\t0\t0\t1\t0\t0\t0\t1\t0\t1\t0\n",
      "1\t1\t0\t1\t0\t1\t1\t0\t1\t1\t0\t1\t1\t0\n",
      "1\t0\t1\t1\t1\t0\t1\t1\t1\t0\t0\t0\t1\t0\n",
      "1\t1\t0\t0\t0\t1\t0\t0\t1\t0\t1\t0\t1\t1\n",
      "1\t0\t1\t0\t0\t0\t1\t1\t0\t1\t1\t0\t1\t0\n",
      "1\t0\t1\t0\t0\t0\t0\t1\t1\t0\t1\t0\t1\t1\n",
      "0\t0\t1\t0\t0\t1\t1\t1\t0\t1\t1\t1\t1\t0\n",
      "0\t0\t0\t0\t1\t0\t0\t1\t0\t0\t1\t0\t1\t0\n",
      "1\t0\t1\t0\t0\t1\t1\t1\t0\t1\t1\t1\t1\t0\n",
      "1\t1\t0\t1\t1\t1\t0\t0\t1\t1\t1\t1\t1\t1\n",
      "0\t1\t1\t0\t0\t1\t1\t1\t0\t0\t0\t1\t1\t0\n",
      "1\t0\t1\t0\t1\t1\t1\t0\t0\t0\t0\t1\t1\t0\n",
      "1\t1\t0\t1\t0\t0\t0\t0\t1\t0\t1\t1\t1\t0\n",
      "0\t0\t1\t1\t1\t1\t1\t0\t1\t1\t1\t1\t1\t0\n",
      "0\t1\t1\t0\t1\t1\t1\t0\t1\t0\t0\t0\t1\t0\n",
      "1\t1\t0\t0\t1\t1\t1\t1\t0\t1\t0\t1\t1\t0\n",
      "1\t0\t0\t0\t1\t1\t1\t1\t1\t1\t0\t0\t1\t0\n",
      "0\t1\t0\t1\t0\t0\t0\t0\t1\t1\t1\t1\t1\t1\n",
      "0\t1\t0\t1\t0\t0\t1\t0\t0\t0\t0\t1\t1\t0\n",
      "0\t1\t0\t1\t1\t0\t1\t1\t1\t1\t0\t0\t1\t0\n",
      "1\t0\t0\t0\t0\t0\t0\t0\t0\t1\t1\t0\t1\t1\n",
      "1\t1\t1\t1\t1\t1\t0\t1\t1\t1\t0\t0\t1\t0\n",
      "1\t1\t1\t0\t0\t0\t1\t0\t1\t1\t1\t0\t1\t1\n",
      "0\t1\t1\t0\t1\t1\t1\t0\t0\t0\t1\t0\t1\t0\n",
      "0\t1\t0\t1\t1\t1\t1\t1\t1\t0\t0\t0\t1\t0\n",
      "0\t1\t1\t1\t1\t1\t0\t0\t0\t0\t1\t0\t1\t0\n",
      "0\t1\t1\t0\t0\t0\t0\t0\t0\t1\t0\t1\t1\t0\n",
      "1\t0\t0\t1\t0\t0\t1\t0\t0\t0\t1\t1\t1\t0\n",
      "1\t0\t1\t1\t1\t1\t1\t0\t0\t0\t0\t0\t1\t0\n",
      "1\t1\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t1\t0\n",
      "0\t0\t0\t1\t0\t1\t1\t1\t1\t1\t1\t0\t1\t0\n",
      "0\t1\t1\t1\t1\t1\t1\t1\t0\t1\t1\t1\t1\t0\n",
      "1\t1\t1\t0\t0\t0\t0\t1\t0\t0\t1\t1\t1\t0\n",
      "0\t0\t1\t0\t1\t0\t0\t1\t0\t1\t1\t0\t1\t1\n",
      "1\t1\t0\t0\t0\t0\t1\t0\t1\t1\t0\t1\t1\t0\n",
      "1\t0\t1\t1\t1\t1\t0\t1\t0\t1\t0\t0\t1\t0\n",
      "0\t1\t0\t0\t0\t1\t1\t0\t0\t1\t0\t1\t1\t1\n",
      "1\t0\t0\t1\t0\t0\t0\t1\t1\t1\t1\t0\t1\t1\n",
      "1\t1\t0\t1\t1\t0\t0\t0\t0\t1\t1\t0\t1\t1\n",
      "1\t0\t0\t0\t1\t0\t0\t0\t1\t0\t0\t1\t1\t0\n",
      "1\t1\t0\t1\t0\t1\t0\t0\t1\t1\t1\t1\t1\t1\n",
      "1\t0\t1\t0\t1\t1\t0\t0\t1\t0\t1\t1\t1\t0\n",
      "1\t1\t0\t0\t1\t0\t0\t1\t0\t0\t1\t0\t1\t0\n",
      "0\t1\t1\t0\t0\t1\t0\t1\t0\t0\t0\t1\t1\t0\n",
      "0\t0\t1\t1\t1\t0\t1\t1\t0\t1\t0\t1\t1\t1\n",
      "1\t1\t0\t0\t0\t0\t0\t0\t1\t1\t0\t0\t1\t0\n",
      "0\t0\t0\t0\t1\t1\t1\t0\t0\t1\t0\t0\t1\t0\n",
      "0\t0\t0\t0\t1\t1\t0\t1\t1\t1\t1\t0\t1\t1\n",
      "1\t0\t0\t1\t0\t0\t0\t0\t0\t1\t0\t1\t1\t1\n",
      "0\t0\t1\t0\t0\t0\t0\t0\t0\t0\t1\t0\t1\t1\n",
      "1\t0\t0\t0\t1\t1\t0\t1\t1\t1\t1\t1\t1\t0\n",
      "1\t1\t1\t0\t0\t0\t1\t0\t1\t1\t0\t0\t1\t0\n",
      "0\t0\t1\t1\t0\t1\t1\t1\t0\t1\t1\t1\t1\t0\n",
      "0\t1\t0\t0\t1\t1\t1\t1\t1\t1\t1\t1\t1\t0\n",
      "1\t0\t0\t1\t1\t0\t0\t0\t1\t1\t0\t0\t1\t0\n",
      "0\t1\t0\t1\t1\t0\t0\t0\t1\t1\t1\t1\t1\t1\n",
      "1\t0\t1\t1\t1\t1\t0\t0\t1\t1\t0\t0\t1\t0\n",
      "0\t0\t1\t1\t1\t1\t1\t0\t1\t1\t1\t0\t1\t1\n",
      "0\t1\t1\t1\t0\t0\t0\t1\t0\t1\t1\t0\t1\t1\n",
      "1\t1\t1\t1\t1\t1\t0\t0\t0\t1\t0\t0\t1\t0\n",
      "1\t0\t1\t0\t0\t1\t0\t1\t1\t0\t1\t1\t1\t0\n",
      "0\t0\t1\t1\t1\t0\t1\t1\t1\t1\t0\t0\t1\t0\n",
      "0\t0\t1\t1\t0\t1\t1\t1\t0\t1\t0\t0\t1\t0\n",
      "0\t0\t0\t0\t0\t1\t0\t1\t0\t0\t0\t0\t1\t0\n",
      "0\t1\t1\t0\t1\t0\t1\t0\t0\t1\t1\t0\t1\t0\n",
      "1\t1\t1\t0\t0\t0\t1\t0\t0\t0\t1\t1\t1\t0\n",
      "0\t1\t0\t1\t0\t0\t0\t0\t1\t1\t0\t1\t1\t0\n",
      "1\t1\t0\t0\t0\t0\t1\t0\t0\t0\t0\t1\t1\t0\n",
      "0\t0\t0\t1\t1\t0\t1\t0\t0\t1\t0\t0\t1\t0\n",
      "1\t1\t0\t1\t0\t0\t0\t0\t0\t1\t1\t0\t1\t1\n",
      "1\t1\t1\t1\t0\t1\t0\t1\t1\t1\t0\t1\t1\t1\n",
      "0\t0\t0\t1\t0\t1\t1\t1\t0\t0\t1\t0\t1\t0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100 11244  100 11244    0     0   311k      0 --:--:-- --:--:-- --:--:--  332k\n"
     ]
    }
   ],
   "source": [
    "# Get the datasets\n",
    "!curl http://huang.eng.unt.edu/CSCE-5218/test.dat\n",
    "!curl http://huang.eng.unt.edu/CSCE-5218/train.dat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rFXHLhnhwiBR"
   },
   "source": [
    "### Build the Perceptron Model\n",
    "\n",
    "You will need to complete some of the function definitions below.  DO NOT import any other libraries to complete this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "cXAsP_lw3QwJ"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import itertools\n",
    "import re\n",
    "\n",
    "# Corpus reader, all columns but the last one are coordinates;\n",
    "#   the last column is the label\n",
    "def read_data(file_name):\n",
    "    f = open(file_name, 'r')\n",
    "\n",
    "    data = []\n",
    "    # Discard header line\n",
    "    f.readline()\n",
    "    for instance in f.readlines():\n",
    "        if not re.search('\\t', instance): continue\n",
    "        instance = list(map(int, instance.strip().split('\\t')))\n",
    "        # Add a dummy input so that w0 becomes the bias\n",
    "        instance = [-1] + instance\n",
    "        data += [instance]\n",
    "    return data\n",
    "\n",
    "\n",
    "def dot_product(array1, array2):\n",
    "    # Return dot product of array1 and array2\n",
    "    return sum(x * y for x, y in zip(array1, array2))\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    # Return output of sigmoid function on x\n",
    "    return 1 / (1 + math.exp(-x))\n",
    "\n",
    "\n",
    "# The output of the model, which for the perceptron is \n",
    "# the sigmoid function applied to the dot product of \n",
    "# the instance and the weights\n",
    "def output(weights, instance):\n",
    "    # Return the output of the model\n",
    "    return sigmoid(dot_product(weights, instance))\n",
    "\n",
    "\n",
    "# Predict the label of an instance; this is the definition of the perceptron\n",
    "# you should output 1 if the output is >= 0.5 else output 0\n",
    "def predict(weights, instance):\n",
    "    # Return the prediction of the model\n",
    "    return 1 if output(weights, instance) >= 0.5 else 0\n",
    "\n",
    "\n",
    "# Accuracy = percent of correct predictions\n",
    "def get_accuracy(weights, instances):\n",
    "    correct = sum(1 if predict(weights, instance) == instance[-1] else 0\n",
    "                  for instance in instances)\n",
    "    return correct * 100 / len(instances)\n",
    "\n",
    "\n",
    "# Train a perceptron with instances and hyperparameters:\n",
    "#       lr (learning rate) \n",
    "#       epochs\n",
    "# The implementation comes from the definition of the perceptron\n",
    "#\n",
    "# Training consists of fitting the parameters which are the weights\n",
    "# that's the only thing training is responsible to fit\n",
    "# (recall that w0 is the bias, and w1..wn are the weights for each coordinate)\n",
    "#\n",
    "# Hyperparameters (lr and epochs) are given to the training algorithm\n",
    "# We are updating weights in the opposite direction of the gradient of the error,\n",
    "# so with a \"decent\" lr we are guaranteed to reduce the error after each iteration.\n",
    "def train_perceptron(instances, lr, epochs):\n",
    "    weights = [0] * (len(instances[0])-1)\n",
    "\n",
    "    for _ in range(epochs):\n",
    "        for instance in instances:\n",
    "            in_value = dot_product(weights, instance)\n",
    "            output_val = sigmoid(in_value)\n",
    "            error = instance[-1] - output_val\n",
    "            for i in range(0, len(weights)):\n",
    "                weights[i] += lr * error * output_val * (1-output_val) * instance[i]\n",
    "\n",
    "    return weights\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "adBZuMlAwiBT"
   },
   "source": [
    "## Run it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "50YvUza-BYQF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#tr: 400, epochs:   5, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n"
     ]
    }
   ],
   "source": [
    "instances_tr = read_data(\"train.dat\")\n",
    "instances_te = read_data(\"test.dat\")\n",
    "lr = 0.005\n",
    "epochs = 5\n",
    "weights = train_perceptron(instances_tr, lr, epochs)\n",
    "accuracy = get_accuracy(weights, instances_te)\n",
    "print(f\"#tr: {len(instances_tr):3}, epochs: {epochs:3}, learning rate: {lr:.3f}; \"\n",
    "      f\"Accuracy (test, {len(instances_te)} instances): {accuracy:.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CBXkvaiQMohX"
   },
   "source": [
    "## Questions\n",
    "\n",
    "Answer the following questions. Include your implementation and the output for each question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YCQ6BEk1CBlr"
   },
   "source": [
    "\n",
    "\n",
    "### Question 1\n",
    "\n",
    "In `train_perceptron(instances, lr, epochs)`, we have the follosing code:\n",
    "```\n",
    "in_value = dot_product(weights, instance)\n",
    "output = sigmoid(in_value)\n",
    "error = instance[-1] - output\n",
    "```\n",
    "\n",
    "Why don't we have the following code snippet instead?\n",
    "```\n",
    "output = predict(weights, instance)\n",
    "error = instance[-1] - output\n",
    "```\n",
    "\n",
    "#### TODO Add your answer here (text only)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is because the train_perceptron function is designed to adjust the weight based on the calculated output (sigmoid(in_value)) and the target output (e.g. [-1]).dot_product(weight, sample) calculates the input detector and then sigmoid(in_value) usesthe sigmoid function to get the output. This output is then compared to the target output sample [-1] to calculate the error used to adjust the weights during backpropagation training.Using the estimate function does not allow us to calculate the error required to adjust the weight. The prediction function is generally used to make predictions after the perceptron has been trained, rather than during training.\n"
     ]
    }
   ],
   "source": [
    "a=\"\"\"This is because the train_perceptron function is designed to adjust the weight based on the calculated output (sigmoid(in_value)) and the target output (e.g. [-1]).dot_product(weight, sample) calculates the input detector and then sigmoid(in_value) usesthe sigmoid function to get the output. This output is then compared to the target output sample [-1] to calculate the error used to adjust the weights during backpropagation training.Using the estimate function does not allow us to calculate the error required to adjust the weight. The prediction function is generally used to make predictions after the perceptron has been trained, rather than during training.\"\"\"\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JU3c3m6YL2rK"
   },
   "source": [
    "### Question 2\n",
    "Train the perceptron with the following hyperparameters and calculate the accuracy with the test dataset.\n",
    "\n",
    "```\n",
    "tr_percent = [5, 10, 25, 50, 75, 100] # percent of the training dataset to train with\n",
    "num_epochs = [5, 10, 20, 50, 100]              # number of epochs\n",
    "lr = [0.005, 0.01, 0.05]              # learning rate\n",
    "```\n",
    "\n",
    "TODO: Write your code below and include the output at the end of each training loop (NOT AFTER EACH EPOCH)\n",
    "of your code.The output should look like the following:\n",
    "```\n",
    "# tr:  20, epochs:   5, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
    "# tr:  20, epochs:  10, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
    "# tr:  20, epochs:  20, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
    "[and so on for all the combinations]\n",
    "```\n",
    "You will get different results with different hyperparameters.\n",
    "\n",
    "#### TODO Add your answer here (code and output in the format above) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "G-VKJOUu2BTp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#tr: 20, epochs: 100, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
      "#tr: 40, epochs: 100, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
      "#tr: 100, epochs: 100, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
      "#tr: 200, epochs: 100, learning rate: 0.005; Accuracy (test, 100 instances): 74.0\n",
      "#tr: 300, epochs: 100, learning rate: 0.005; Accuracy (test, 100 instances): 78.0\n",
      "#tr: 400, epochs: 100, learning rate: 0.005; Accuracy (test, 100 instances): 77.0\n",
      "#tr: 20, epochs: 100, learning rate: 0.010; Accuracy (test, 100 instances): 68.0\n",
      "#tr: 40, epochs: 100, learning rate: 0.010; Accuracy (test, 100 instances): 68.0\n",
      "#tr: 100, epochs: 100, learning rate: 0.010; Accuracy (test, 100 instances): 71.0\n",
      "#tr: 200, epochs: 100, learning rate: 0.010; Accuracy (test, 100 instances): 78.0\n",
      "#tr: 300, epochs: 100, learning rate: 0.010; Accuracy (test, 100 instances): 80.0\n",
      "#tr: 400, epochs: 100, learning rate: 0.010; Accuracy (test, 100 instances): 80.0\n",
      "#tr: 20, epochs: 100, learning rate: 0.050; Accuracy (test, 100 instances): 64.0\n",
      "#tr: 40, epochs: 100, learning rate: 0.050; Accuracy (test, 100 instances): 69.0\n",
      "#tr: 100, epochs: 100, learning rate: 0.050; Accuracy (test, 100 instances): 77.0\n",
      "#tr: 200, epochs: 100, learning rate: 0.050; Accuracy (test, 100 instances): 76.0\n",
      "#tr: 300, epochs: 100, learning rate: 0.050; Accuracy (test, 100 instances): 77.0\n",
      "#tr: 400, epochs: 100, learning rate: 0.050; Accuracy (test, 100 instances): 80.0\n"
     ]
    }
   ],
   "source": [
    "instances_tr = read_data(\"train.dat\")\n",
    "instances_te = read_data(\"test.dat\")\n",
    "tr_percent = [5, 10, 25, 50, 75, 100] # percent of the training dataset to train with\n",
    "num_epochs = [5, 10, 20, 50, 100]     # number of epochs\n",
    "lr_array = [0.005, 0.01, 0.05]        # learning rate\n",
    "\n",
    "for lr in lr_array:\n",
    "  for tr_size in tr_percent:\n",
    "    for epochs in num_epochs:\n",
    "      size =  round(len(instances_tr)*tr_size/100)\n",
    "      pre_instances = instances_tr[0:size]\n",
    "      weights = train_perceptron(pre_instances, lr, epochs)\n",
    "      accuracy = get_accuracy(weights, instances_te)\n",
    "    print(f\"#tr: {len(pre_instances):0}, epochs: {epochs:3}, learning rate: {lr:.3f}; \"\n",
    "            f\"Accuracy (test, {len(instances_te)} instances): {accuracy:.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OFB9MtwML24O"
   },
   "source": [
    "### Question 3\n",
    "Write a couple paragraphs interpreting the results with all the combinations of hyperparameters. Drawing a plot will probably help you make a point. In particular, answer the following:\n",
    "- A. Do you need to train with all the training dataset to get the highest accuracy with the test dataset?\n",
    "- B. How do you justify that training the second run obtains worse accuracy than the first one (despite the second one uses more training data)?\n",
    "   ```\n",
    "#tr: 100, epochs:  20, learning rate: 0.050; Accuracy (test, 100 instances): 71.0\n",
    "#tr: 200, epochs:  20, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
    "```\n",
    "- C. Can you get higher accuracy with additional hyperparameters (higher than `80.0`)?\n",
    "- D. Is it always worth training for more epochs (while keeping all other hyperparameters fixed)?\n",
    "\n",
    "#### TODO: Add your answer here (code and text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#tr: 100, epochs:  20, learning rate: 0.050; Accuracy (test, 100 instances): 70.0\n",
      "#tr: 200, epochs:  20, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
      "A.No, you dont need to train with_all training data to get the highest accuracy with_test data.The quality of training data depends on many factors, such_as the complexity of the problem,the representativeness of the dataset, and_the capacity of the model.\n",
      "\n",
      "B.Even_if more training data is used, the accuracy of the second run will be poor.Overfitting occurs when the model learns to remember training data rather than using it. As training data increases, the model can become overly reactive, especially if the model is complex or the dataset is noisy.\n",
      "\n",
      "C.Additional hyperparameters can be used to achieve higher accuracy, such as complex algorithms, optimizations or assembly methods. However, achieving an accuracy higher than 80.0 by tuning the given hyperparameters can be difficult, especially if the dataset is noisy or the problem is_complex.\n",
      "D.No, it is_not always necessary to train repeatedly. Too much training can lead to overfitting, especially when the models capacity_is high relative to the complexity of the problem_or the data set_is small.Performance should be monitored to ensure that performance and_training are stopped using strategies such as early termination_if performance is_low_or begins to decline.\n"
     ]
    }
   ],
   "source": [
    "a=\"\"\"A.No, you dont need to train with_all training data to get the highest accuracy with_test data.The quality of training data depends on many factors, such_as the complexity of the problem,the representativeness of the dataset, and_the capacity of the model.\\n\"\"\"\n",
    "\n",
    "b=\"\"\"B.Even_if more training data is used, the accuracy of the second run will be poor.Overfitting occurs when the model learns to remember training data rather than using it. As training data increases, the model can become overly reactive, especially if the model is complex or the dataset is noisy.\\n\"\"\"\n",
    "\n",
    "instances_tr = read_data(\"train.dat\")\n",
    "instances_te = read_data(\"test.dat\")\n",
    "lr_1 = 0.050\n",
    "epochs_1 = 20\n",
    "lr_2 = 0.005\n",
    "epochs_2 = 20\n",
    "weights_1 = train_perceptron(instances_tr[:100], lr_1, epochs_1)\n",
    "accuracy_1 = get_accuracy(weights_1, instances_te)\n",
    "weights_2 = train_perceptron(instances_tr[100:300], lr_2, epochs_2)\n",
    "accuracy_2 = get_accuracy(weights_2, instances_te)\n",
    "print(f\"#tr: {len(instances_tr[:100])}, epochs: {epochs_1:3}, learning rate: {lr_1:.3f}; \"\n",
    "      f\"Accuracy (test, {len(instances_te)} instances): {accuracy_1:.1f}\")\n",
    "print(f\"#tr: {len(instances_tr[100:300]):3}, epochs: {epochs_2:3}, learning rate: {lr_2:.3f}; \"\n",
    "      f\"Accuracy (test, {len(instances_te)} instances): {accuracy_2:.1f}\")\n",
    "\n",
    "\n",
    "c=\"\"\"C.Additional hyperparameters can be used to achieve higher accuracy, such as complex algorithms, optimizations or assembly methods. However, achieving an accuracy higher than 80.0 by tuning the given hyperparameters can be difficult, especially if the dataset is noisy or the problem is_complex.\"\"\"\n",
    "\n",
    "d=\"\"\"D.No, it is_not always necessary to train repeatedly. Too much training can lead to overfitting, especially when the models capacity_is high relative to the complexity of the problem_or the data set_is small.Performance should be monitored to ensure that performance and_training are stopped using strategies such as early termination_if performance is_low_or begins to decline.\"\"\"\n",
    "print(a)\n",
    "print(b)\n",
    "print(c)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "38rA_Kp3wiBX"
   },
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "HW2_The_Perceptron.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
